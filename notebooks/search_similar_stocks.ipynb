{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7131135",
   "metadata": {},
   "source": [
    "# Build and compress index files and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496073a",
   "metadata": {},
   "source": [
    "### *Notes on data transformation*  \n",
    "Raw values can be misleading since we focus on patterns.  \n",
    "There are some possible ways of transforming data:  \n",
    "1. Divide by first value - $x_t^* = \\frac{x_t}{x_1}$\n",
    "2. Standardize - $x_t^* = \\frac{x_t-\\bar x}{\\sigma}$\n",
    "3. Scale to range (0, 1) - $x_t^* = \\frac{x_t-x_{min}}{x_{max}-x_{min}}$\n",
    "\n",
    "This project uses **3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed923b",
   "metadata": {},
   "source": [
    "### *Notes on similarity search*\n",
    "Some metrics to calculate similarity:\n",
    "1. Euclidean distance - $\\|\\mathbf{x}-\\mathbf{y}\\|_2$\n",
    "2. Cosine similarity - $\\frac{\\mathbf{x}\\cdot\\mathbf{y}}{\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2}$\n",
    "3. Dynamic time wrapping\n",
    "\n",
    "This project uses **1** with additional processing to lower memory uses and speed up searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d8f22",
   "metadata": {},
   "source": [
    "## ===== Part 1: Stock data processing ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TICKERS = 200  # int or None for all tickers\n",
    "DAYS_WINDOW = 50\n",
    "PERIOD = \"2y\"  # one of 1y, 2y, 5y, 10y, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf38f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_gone_wrong.simularity.ticker import get_us_tickers\n",
    "\n",
    "ticker_symbols = get_us_tickers()\n",
    "if NUM_TICKERS is not None:\n",
    "    ticker_symbols = random.choices(ticker_symbols, k=NUM_TICKERS)\n",
    "print(len(ticker_symbols), \"tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f981d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "tickers = yf.Tickers(\",\".join(ticker_symbols))\n",
    "history_df = cast(pd.DataFrame, tickers.history(period=PERIOD))\n",
    "print(len(history_df), \"days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8968823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_gone_wrong.simularity.ticker import process_history, shorlist_history\n",
    "\n",
    "df = process_history(history_df)\n",
    "if NUM_TICKERS is None:\n",
    "    df = shorlist_history(df, 5000)\n",
    "metrics: list[str] = list(df.columns.levels[0].values)\n",
    "\n",
    "if \"Close\" in metrics and \"Volume\" in metrics:\n",
    "    # some cells may have a NaN Close but float Volume\n",
    "    df[\"Volume\"] = df[\"Volume\"].where(~df[\"Close\"].isna(), other=pd.NA)\n",
    "\n",
    "print(df.columns.levels[0], df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# each metric should have the same nan masks\n",
    "nan_masks = [df[c].isna().to_numpy() for c in metrics]\n",
    "assert np.all(nan_masks == nan_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3e15e",
   "metadata": {},
   "source": [
    "## ===== Part 2: Data indexing ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = f\"us_stock_{DAYS_WINDOW}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83474786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from stock_gone_wrong.simularity.preprocess import sliding_metrics_series_view\n",
    "\n",
    "# to make sure there are data after the window\n",
    "metrics_series, non_nans = sliding_metrics_series_view(df, DAYS_WINDOW, DAYS_WINDOW)\n",
    "for m in metrics_series:\n",
    "    # sort of standardise the samples by clamping the data\n",
    "    metrics_series[m] = minmax_scale(metrics_series[m], feature_range=(0, 1), axis=1)\n",
    "print(non_nans.shape, metrics_series[metrics[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_gone_wrong.simularity.indexing import (create_index,\n",
    "                                                  create_index_meta)\n",
    "\n",
    "metric_indices = {m: create_index(s) for m, s in metrics_series.items()}\n",
    "meta_df = create_index_meta(non_nans, df[\"Close\"].columns, df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff00acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_gone_wrong.simularity.indexing import DataPack\n",
    "\n",
    "DataPack(df, metric_indices, meta_df).archive(DATA_FILE)\n",
    "data_pack = DataPack.extract(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "data_pack = DataPack.extract(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8465649",
   "metadata": {},
   "source": [
    "## ===== Part 3: Query ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32244759",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = \"Close\"\n",
    "TICKER = \"TSLA\"\n",
    "SHOW_FORECAST = True\n",
    "\n",
    "if SHOW_FORECAST:\n",
    "    import warnings\n",
    "\n",
    "    warnings.warn(\n",
    "        \"SHOW_FORECAST is set to True. But keep in mind that the calculations are based on the scaled data, which will lead to underestimating the uncertainty. The results have little predictive power.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562253d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = yf.Tickers(TICKER).history(\"6mo\")\n",
    "query_df = process_history(query_df)\n",
    "query_df.columns = query_df.columns.droplevel(1)\n",
    "\n",
    "raw_query_data = query_df[METRICS][:DAYS_WINDOW].to_numpy()\n",
    "query_data = minmax_scale(raw_query_data, feature_range=(0, 1))\n",
    "query_data = query_data.reshape((1, -1))\n",
    "print(query_df.shape, query_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dist, *_), (idx, *_) = data_pack.indices[METRICS].search(query_data, 20)\n",
    "print(dist)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from stock_gone_wrong.simularity.preprocess import extended_minmax_scale\n",
    "from stock_gone_wrong.simularity.visual import calculate_PI, format_plot\n",
    "\n",
    "similar_tickers = [data_pack.meta.loc[i][\"Ticker\"] for i in idx]\n",
    "print(sorted(list(set(similar_tickers))))\n",
    "\n",
    "x_days = np.arange(-DAYS_WINDOW, DAYS_WINDOW)\n",
    "scaled_series = []\n",
    "for i in idx:\n",
    "    series = data_pack.get_series(i, METRICS, DAYS_WINDOW * 2)\n",
    "    series = extended_minmax_scale(series, (0, 1), fit_window=slice(0, DAYS_WINDOW))\n",
    "    plt.plot(x_days, series, color=\"grey\", alpha=0.3)\n",
    "    scaled_series.append(series)\n",
    "scaled_data = np.stack(scaled_series)\n",
    "\n",
    "\n",
    "if SHOW_FORECAST:\n",
    "    series_mean = scaled_data.mean(axis=0)\n",
    "    plt.plot(x_days, series_mean, label=\"Mean\")\n",
    "    pi_lower, pi_upper = calculate_PI(scaled_data)\n",
    "    plt.fill_between(\n",
    "        x_days, pi_lower, pi_upper, alpha=0.2, label=\"95% Prediction Interval\"\n",
    "    )\n",
    "plt.axvline(-1, color=\"red\", alpha=0.5, linestyle=\"--\", label=\"Last record\")\n",
    "plt.plot(x_days[:DAYS_WINDOW], query_data[0], label=TICKER)\n",
    "\n",
    "format_plot(TICKER, METRICS)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
